{
  "package": {
    "promptflow.tools.embedding.embedding": {
      "name": "Embedding",
      "description": "Use Open AI's embedding model to create an embedding vector representing the input text.",
      "type": "python",
      "module": "promptflow.tools.embedding",
      "function": "embedding",
      "inputs": {
        "connection": {
          "type": [
            "AzureOpenAIConnection",
            "OpenAIConnection"
          ]
        },
        "deployment_name": {
          "type": [
            "string"
          ],
          "enabled_by": "connection",
          "enabled_by_type": [
            "AzureOpenAIConnection"
          ],
          "capabilities": {
            "completion": false,
            "chat_completion": false,
            "embeddings": true
          },
          "model_list": [
            "text-embedding-ada-002",
            "text-search-ada-doc-001",
            "text-search-ada-query-001"
          ]
        },
        "model": {
          "type": [
            "string"
          ],
          "enabled_by": "connection",
          "enabled_by_type": [
            "OpenAIConnection"
          ],
          "enum": [
            "text-embedding-ada-002",
            "text-search-ada-doc-001",
            "text-search-ada-query-001"
          ]
        },
        "input": {
          "type": [
            "string"
          ]
        }
      },
      "package": "promptflow-tools",
      "package_version": "1.0.0"
    }
  },
  "code": {
    "find_references.py": {
      "type": "python",
      "inputs": {
        "main_text": {
          "type": [
            "string"
          ]
        },
        "reference_text": {
          "type": [
            "string"
          ]
        }
      },
      "source": "find_references.py",
      "function": "find_references"
    },
    "summary_prompt.jinja2": {
      "type": "prompt",
      "inputs": {
        "text": {
          "type": [
            "string"
          ]
        }
      },
      "source": "summary_prompt.jinja2"
    },
    "gemini_llm.py": {
      "type": "python",
      "inputs": {
        "input1": {
          "type": [
            "string"
          ]
        },
        "conn": {
          "type": [
            "CustomConnection"
          ]
        }
      },
      "source": "gemini_llm.py",
      "function": "my_python_tool"
    },
    "continue_prompt.jinja2": {
      "type": "prompt",
      "inputs": {
        "previous_summary_prompt": {
          "type": [
            "string"
          ]
        },
        "current_summary": {
          "type": [
            "string"
          ]
        }
      },
      "source": "continue_prompt.jinja2"
    },
    "gemini_continue_llm.py": {
      "type": "python",
      "inputs": {
        "conn": {
          "type": [
            "CustomConnection"
          ]
        },
        "continue_prompt": {
          "type": [
            "string"
          ]
        }
      },
      "source": "gemini_continue_llm.py",
      "function": "my_python_tool"
    },
    "combine_output.py": {
      "type": "python",
      "inputs": {
        "case_summary": {
          "type": [
            "string"
          ]
        },
        "case_reference": {
          "type": [
            "object"
          ]
        },
        "llm_reference": {
          "type": [
            "string"
          ]
        }
      },
      "source": "combine_output.py",
      "function": "my_python_tool"
    },
    "create_faiss_index.py": {
      "type": "python",
      "inputs": {
        "connection": {
          "type": [
            "OpenAIConnection"
          ]
        },
        "case_text": {
          "type": [
            "string"
          ]
        }
      },
      "source": "create_faiss_index.py",
      "function": "create_faiss_index"
    },
    "find_context.py": {
      "type": "python",
      "inputs": {
        "connection": {
          "type": [
            "OpenAIConnection"
          ]
        },
        "created_index": {
          "type": [
            "bool"
          ]
        },
        "case_summary": {
          "type": [
            "string"
          ]
        }
      },
      "source": "find_context.py",
      "function": "find_context"
    }
  }
}